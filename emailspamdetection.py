# -*- coding: utf-8 -*-
"""EmailSpamDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15r4VBUBtdITw4KpY-KgBOJfGIGck23KN
"""

# 1. IMPORTING LIBRARIES
import pickle
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style("white")
import matplotlib.pyplot as plt
import string
from pickle import dump
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import nltk
from nltk.corpus import stopwords
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
nltk.download('stopwords')

# 2. LOADING AND INSPECTING THE DATA

# Load the dataset
dataset = pd.read_csv('/content/emails.csv')
dataset.shape

# shows the first 5 records
dataset.head()

# Show dataset info
dataset.info()

# Show dataset statistics
dataset.describe()

# 3. DATA VISUALIZATION

# Optional: Set plot style
sns.set_style("whitegrid")

# Plot the spam frequencies
plt.figure(dpi=100)
sns.countplot(x='spam', data=dataset, palette='pastel')
plt.title("Spam Frequencies")
plt.xlabel("Label (0 = Not Spam, 1 = Spam)")
plt.ylabel("Count")
plt.show()

# 4. DATA CLEANING

# Check for missing data for each column
dataset.isnull().sum()

# Check for duplicates and remove them
dataset.drop_duplicates(inplace=True)

# 5. TEXT PREPROCESSING

# Cleaning data from punctuation and stopwords and then tokenizing it into words (tokens)
def process(text):
    nopunc = [char for char in text if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
    return clean

# 6. FEATURE EXTRACTION

# Fit the CountVectorizer to data
message = CountVectorizer(analyzer=process).fit_transform(dataset['text'])

# 7. SPLIT DATA INTO TRAINING AND TESTING SETS

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(message, dataset['spam'], test_size=0.20, random_state=0)

# 8. TRAINING THE MODEL

# Model creation
model = MultinomialNB()

# Model training
model.fit(X_train, y_train)

# 9. SAVE MODEL AND VECTORIZER

from pickle import dump
import os

# Create directory if it doesn't exist
os.makedirs("models", exist_ok=True)

# Save the trained vectorizer
dump(vectorizer, open("models/vectorizer.pkl", "wb"))
# Save the trained model
dump(model, open("models/spam_model.pkl", "wb"))

# Model saving
dump(model, open("models/model.pkl", 'wb'))

#10. MODEL EVALUATION

# Model predictions on test set
y_pred = model.predict(X_test)

# Model Evaluation | Classification report
classification_report(y_test, y_pred)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(dpi=100)
sns.heatmap(cm, annot=True)
plt.title("Confusion matrix")
plt.show()

# Model Evaluation | Accuracy
accuracy = accuracy_score(y_test, y_pred)
accuracy * 100

#11.Final Version: Real-Time Spam Detector

# Load model and vectorizer for real-time prediction
from pickle import load

# Load vectorizer and model
vectorizer = load(open("models/vectorizer.pkl", "rb"))
model = load(open("models/spam_model.pkl", "rb"))

# Real-time prediction function
def predict_email(text):
    processed_text = vectorizer.transform([text])
    prediction = model.predict(processed_text)
    return "Spam" if prediction[0] == 1 else "Not Spam"

# Try real-time input
user_input = input("Enter an email message: ")
print("Prediction:", predict_email(user_input))

